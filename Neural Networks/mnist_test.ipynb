{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Network with MNIST Dataset\n",
    "For this test, I will use Scikit-Learn to download the dataset, since it has a built-in function for it. Keep in mind that the neural network in this notebook is not optimized for these kinds of tasks. Also, a convolutional network might be more appropriate here, instead of a fully-connected feedforward one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andres/miniconda3/envs/ml_book/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from activations import *\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations\n",
    "I will convert the target labels into one-hot encoded vectors so that the neural network is easier to train.\n",
    "At the same time, I will normalize the data pixel data to be in the range [-1, 1] to help the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(mnist.target.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now transform the target data using the encoder\n",
    "encoded_targets = encoder.transform(mnist.target.reshape(-1,1)).toarray()\n",
    "encoded_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_data = scaler.fit_transform(mnist.data)\n",
    "\n",
    "encoded_targets = scaler.fit_transform(encoded_targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Mini Dataset for Training Toy Example\n",
    "The full MNIST dataset has 70000 samples and this neural network is not designed for efficiency. Therefore, I will only use a fraction of the data to check how the network behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use only a portion of the dataset\n",
    "\n",
    "train_data_size = 300\n",
    "test_data_size  = 25\n",
    "\n",
    "X_train = scaled_data[:train_data_size]        #mnist.data[:data_size]\n",
    "y_train = encoded_targets[:train_data_size]    #mnist.target[:data_size]   #toarray() converts the sparse matrix output from one-hot encoding into a numpy array\n",
    "\n",
    "X_test = scaled_data[train_data_size:train_data_size+test_data_size]       #mnist.data[data_size:data_size+200]\n",
    "y_test = encoded_targets[train_data_size:train_data_size+test_data_size]  #mnist.target[data_size:data_size+200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is taken from the book \"Hands-on Machine Learning\": \n",
    "# (ref. link) https://amzn.to/43SyF81\n",
    "\n",
    "def plot_digit(image_data):\n",
    "    image = image_data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label (one-hot encoded vector): [-1. -1. -1. -1. -1. -1.  1. -1. -1. -1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_idx = 155\n",
    "img = X_train[_idx]\n",
    "plot_digit(img)\n",
    "print(f\"Image Label (one-hot encoded vector): {y_train[_idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.97647059, -0.85882353, -0.85882353,\n",
       "        -0.85882353, -0.01176471,  0.06666667,  0.37254902, -0.79607843,\n",
       "         0.30196078,  1.        ,  0.9372549 , -0.00392157, -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.76470588, -0.71764706,\n",
       "        -0.2627451 ,  0.20784314,  0.33333333,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.76470588,  0.34901961,\n",
       "         0.98431373,  0.89803922,  0.52941176, -0.49803922, -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.61568627,  0.86666667,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.96862745, -0.27058824, -0.35686275,\n",
       "        -0.35686275, -0.56078431, -0.69411765, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.85882353,  0.71764706,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.98431373,  0.55294118,\n",
       "         0.42745098,  0.9372549 ,  0.89019608, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.37254902,  0.22352941,\n",
       "        -0.16078431,  0.98431373,  0.98431373,  0.60784314, -0.91372549,\n",
       "        -1.        , -0.6627451 ,  0.20784314, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.89019608,\n",
       "        -0.99215686,  0.20784314,  0.98431373, -0.29411765, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        ,  0.09019608,  0.98431373,  0.49019608, -0.98431373,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.91372549,  0.49019608,  0.98431373, -0.45098039,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.7254902 ,  0.89019608,  0.76470588,\n",
       "         0.25490196, -0.15294118, -0.99215686, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.36470588,  0.88235294,\n",
       "         0.98431373,  0.98431373, -0.06666667, -0.80392157, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.64705882,\n",
       "         0.45882353,  0.98431373,  0.98431373,  0.17647059, -0.78823529,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.8745098 , -0.27058824,  0.97647059,  0.98431373,  0.46666667,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        ,  0.95294118,  0.98431373,  0.95294118,\n",
       "        -0.49803922, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.63921569,\n",
       "         0.01960784,  0.43529412,  0.98431373,  0.98431373,  0.62352941,\n",
       "        -0.98431373, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.69411765,  0.16078431,  0.79607843,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.96078431,  0.42745098,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.81176471, -0.10588235,  0.73333333,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.57647059, -0.38823529, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.81960784, -0.48235294,\n",
       "         0.67058824,  0.98431373,  0.98431373,  0.98431373,  0.98431373,\n",
       "         0.55294118, -0.36470588, -0.98431373, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.85882353,  0.34117647,  0.71764706,  0.98431373,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.52941176, -0.37254902,\n",
       "        -0.92941176, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -0.56862745,\n",
       "         0.34901961,  0.77254902,  0.98431373,  0.98431373,  0.98431373,\n",
       "         0.98431373,  0.91372549,  0.04313725, -0.91372549, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        ,  0.06666667,\n",
       "         0.98431373,  0.98431373,  0.98431373,  0.6627451 ,  0.05882353,\n",
       "         0.03529412, -0.8745098 , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here is the same data as a numpy array\n",
    "img.reshape(28,28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Create a Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network hyperparameters\n",
    "\n",
    "#-- topology\n",
    "n_features = X_train.shape[1]\n",
    "n_hidden_1 = int(n_features * 0.7) \n",
    "n_hidden_2 = int(n_hidden_1 * 0.5)\n",
    "n_outputs  = y_train.shape[1]\n",
    "\n",
    "topology   = [n_features, n_hidden_1, n_hidden_2, n_outputs]\n",
    "\n",
    "#-- learning\n",
    "learning_rate = 0.01\n",
    "momentum = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 548, 274, 10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neural_networks import NeuralNet\n",
    "\n",
    "nnet = NeuralNet(\n",
    "    topology=topology,\n",
    "    learning_rate=learning_rate,\n",
    "    momentum=momentum, \n",
    "    init_method='xavier',\n",
    "    hidden_activation_func=tanh,\n",
    ")\n",
    "\n",
    "nnet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583356"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.n_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18014632,  0.07274652,  0.00701501,  0.0061341 ,  0.07958543,\n",
       "         0.02260754, -0.05598693, -0.11431937, -0.01468035,  0.09811637]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.feedforward(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "\t-> training step: :0/150\n",
      "\t\t* current error: 570.9092380208318, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :20/150\n",
      "\t\t* current error: 679.7750144838453, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :40/150\n",
      "\t\t* current error: 688.6783956937184, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :60/150\n",
      "\t\t* current error: 687.2593745472036, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :80/150\n",
      "\t\t* current error: 696.4885057787252, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :100/150\n",
      "\t\t* current error: 667.5289436057762, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :120/150\n",
      "\t\t* current error: 668.3797104847773, threshold: 1e-10\n",
      "\n",
      "---------------------------------------------\n",
      "\t-> training step: :140/150\n",
      "\t\t* current error: 670.6423589344782, threshold: 1e-10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "664.8337823106687"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.train(X_train, y_train, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8902715231160372\n",
      "1.9166259143751285\n",
      "1.6776054254066963\n",
      "1.987515793990009\n",
      "1.9152625194023756\n",
      "1.9166132213807208\n",
      "1.9835060143534464\n",
      "1.916668161123029\n",
      "1.935775674720899\n",
      "1.9863786366196607\n",
      "1.9863000965807855\n",
      "1.6756066367832818\n",
      "1.8913183311303492\n",
      "1.9151733640590947\n",
      "2.002954441634004\n",
      "1.98638572082803\n",
      "1.983836201706499\n",
      "1.9358138656865487\n",
      "1.9362188460338488\n",
      "1.915406882095307\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    _x = X_test[[i]]\n",
    "    _y = y_test[[i]]\n",
    "\n",
    "    _learned_y = nnet.feedforward(_x)\n",
    "    error = mean_squared_error(_y, _learned_y)\n",
    "\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9999951 , -0.99998093, -0.99999378, -0.99994623, -0.9996368 ,\n",
       "        -0.99992235, -0.99998145, -0.99997073, -0.99998295, -0.99995209]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_learned_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
